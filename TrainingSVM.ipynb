{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Meysam Amirsardari**\n",
        "SID: 98106218"
      ],
      "metadata": {
        "id": "wsZ1hEGahSxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Datasets from Kaggle: "
      ],
      "metadata": {
        "id": "CFIpMGysd6NG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle\n",
        "#! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "tcooGcPCUDiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d aashwingupta3012/human-faces\n",
        "\n",
        "#https://www.kaggle.com/datasets/niten19/face-shape-dataset\n",
        "#https://www.kaggle.com/datasets/greatgamedota/ffhq-face-data-set"
      ],
      "metadata": {
        "id": "_Kjyrv9aUEXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip \"/content/human-faces.zip\""
      ],
      "metadata": {
        "id": "r0wZs-blmMB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports:"
      ],
      "metadata": {
        "id": "yyLqZjmheP--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from time import time\n",
        "import errno\n",
        "import shutil\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report, log_loss, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import seaborn as sns\n",
        "import seaborn as sns; sns.set()\n",
        "from skimage import data, color, feature\n",
        "import skimage.data\n",
        "from sklearn.feature_extraction.image import PatchExtractor\n",
        "from skimage import data, transform\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "i5NP2dc-QtPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Faces:"
      ],
      "metadata": {
        "id": "Qs6Ar7lnu48z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "people = fetch_lfw_people()\n",
        "faceImages = people.images"
      ],
      "metadata": {
        "id": "HGM4BNiAQhmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = []\n",
        "y = []\n",
        "descriptor = cv2.HOGDescriptor()\n",
        "\n",
        "for i in range(len(faceImages)):\n",
        "    image = cv2.resize(faceImages[i], (128, 128))\n",
        "    image = feature.hog(image)\n",
        "    image = image.transpose()\n",
        "    x.append(image)\n",
        "    y.append(1)"
      ],
      "metadata": {
        "id": "diq-nLzLSBh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_patches(img, N, scale=1.0, size=faceImages[0].shape):\n",
        "    extracted_patch_size = tuple((scale * np.array(size)).astype(int))\n",
        "    extractor = PatchExtractor(patch_size=extracted_patch_size,\n",
        "                               max_patches=N, random_state=0)\n",
        "    patches = extractor.transform(img[np.newaxis])\n",
        "    if scale != 1:\n",
        "        patches = np.array([transform.resize(patch, size)\n",
        "                            for patch in patches])\n",
        "    return patches\n",
        "\n",
        "imgs_to_use = ['camera', 'text', 'coins', 'moon',\n",
        "               'page', 'clock', 'immunohistochemistry',\n",
        "               'chelsea', 'coffee', 'hubble_deep_field']\n",
        "images = [color.rgb2gray(getattr(data, name)())\n",
        "          for name in imgs_to_use]\n",
        "\n",
        "nonfaces = np.vstack([extract_patches(im, 1000, scale)\n",
        "                              for im in images for scale in [0.5, 1.0, 2.0]])\n",
        "nonfaces = nonfaces[0:10000]\n",
        "\n",
        "for i in range(nonfaces.shape[0]):\n",
        "    image = cv2.resize(nonfaces[i, :, :], (128, 128))\n",
        "    image = feature.hog(image)\n",
        "    image = image.transpose()\n",
        "    x.append(image)\n",
        "    y.append(0)"
      ],
      "metadata": {
        "id": "fMUPNCFIIVJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f7409d1-6912-4e06-a843-1a50ae378930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**More data:**"
      ],
      "metadata": {
        "id": "Vjfqz3Q_KrvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base = '/content/afhq/train/wild'\n",
        "names = os.listdir(base)\n",
        "\n",
        "for i,name in enumerate(names):\n",
        "    img = cv2.imread(os.path.join(base, name), 0)\n",
        "    image = cv2.resize(img, (64, 64))\n",
        "    image = feature.hog(image)\n",
        "    image = image.transpose()\n",
        "    x.append(image)\n",
        "    y.append(0)"
      ],
      "metadata": {
        "id": "5Fz3R1kMu95J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DON'T RUN THIS!!!!**"
      ],
      "metadata": {
        "id": "H5htBUFeu-vR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "winSize = (64,64)\n",
        "blockSize = (16,16)\n",
        "blockStride = (8,8)\n",
        "cellSize = (8,8)\n",
        "nbins = 9\n",
        "derivAperture = 1\n",
        "winSigma = 4\n",
        "histogramNormType = 0\n",
        "L2HysThreshold = 2.01e-01\n",
        "gammaCorrection = 0\n",
        "nlevels = 64\n",
        "hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins,derivAperture, winSigma,\n",
        "                        histogramNormType, L2HysThreshold, gammaCorrection, nlevels)\n",
        "winStride = (8,8)\n",
        "padding = (8,8)\n",
        "locations = ((10,20),)\n",
        "out = hog.compute(image, winStride, padding, locations)"
      ],
      "metadata": {
        "id": "BaCQ8iLOr89v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training:"
      ],
      "metadata": {
        "id": "XE5SS6Iufso2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.05, shuffle=True)\n",
        "\n",
        "cross_val_score(GaussianNB(), X_train, y_train)"
      ],
      "metadata": {
        "id": "quUoUxz-jvw4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b9f706c-837e-4144-8372-94e96730904d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.97100793, 0.97258722, 0.96896239, 0.97077481, 0.96964205])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection  import GridSearchCV\n",
        "grid = GridSearchCV(LinearSVC(), {'C': [1.0, 2.0, 4.0, 8.0]})\n",
        "grid.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Z3-cKCMoL9QJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "890e55cf-9fc8-4d30-a330-2cc2253a3c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1198: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  sample_weight,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1198: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  sample_weight,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1198: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  sample_weight,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1198: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  sample_weight,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1198: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  sample_weight,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1198: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  sample_weight,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1198: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  sample_weight,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1198: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  sample_weight,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=LinearSVC(), param_grid={'C': [1.0, 2.0, 4.0, 8.0]})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "model = grid.best_estimator_\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "bRn-cAZHMKuz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39832526-72ac-4b8b-e4b0-8f80bb841993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1198: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  sample_weight,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC()"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Acc = %.2lf\" % (accuracy*100))"
      ],
      "metadata": {
        "id": "P1ijemIwunNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e83dd133-96cd-4ba6-a444-586270ecf2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc = 99.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(model, 'SVMmodel.sav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bneI9iW0ox9j",
        "outputId": "9fa0339c-7a92-491b-bd45-a37917b020d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SVMmodel.sav']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reloading trained model:"
      ],
      "metadata": {
        "id": "LztZcqIkgGWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "model = pickle.load(open('SVMmodel.sav', 'rb'))"
      ],
      "metadata": {
        "id": "UuYSFdGCLle2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test1:**"
      ],
      "metadata": {
        "id": "wCrv3227ONwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imutils\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def sliding_window(image, stepSize, windowSize):\n",
        "  for y in range(0, image.shape[0], stepSize):\n",
        "    for x in range(0, image.shape[1], stepSize):\n",
        "      yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])\n",
        "\n",
        "def pyramid(image, scale=1.4, minSize=(32, 32)):\n",
        "    yield image \n",
        "\n",
        "    while True:\n",
        "        w = int(image.shape[1] / scale)     \n",
        "        image = imutils.resize(image, width=w)\n",
        "\n",
        "        if image.shape[0] < minSize[1] or image.shape[1] > minSize[0]:\n",
        "            break \n",
        "        yield image\n",
        "\n",
        "test_image = skimage.data.astronaut()\n",
        "test_image = skimage.color.rgb2gray(test_image)\n",
        "test_image = skimage.transform.rescale(test_image, 0.5)\n",
        "image = test_image[:160, 40:180]\n",
        "\n",
        "bboxes = []\n",
        "(winW, winH) = (128, 128)\n",
        "\n",
        "for resized in pyramid(image, scale=1.4):\n",
        "  for (x, y, window) in sliding_window(resized, stepSize=32, windowSize=(winW, winH)):\n",
        "    if window.shape[0] != winH or window.shape[1] != winW: continue\n",
        "    fd = feature.hog(window)\n",
        "    pred = model.predict([fd])\n",
        "    \n",
        "    if pred==1:\n",
        "      bboxes.append((x, y, winW, winH))\n",
        "      \n",
        "    clone = resized.copy()\n",
        "    cv2.rectangle(clone, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\n",
        "    cv2_imshow(clone)\n",
        "    cv2.waitKey(1)\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "Z = []\n",
        "\n",
        "for(x, y, w, h) in bboxes:\n",
        "  image = cv2.rectangle(image, (x, y), \n",
        "                    (x + w, y + h), \n",
        "                    (255, 0, 0), 2)  \n",
        "  X.append(x+w/2)\n",
        "  Y.append(y+h/2)\n",
        "  Z.append(1)  \n",
        "\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "_3fPxM1EMqK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Density map:"
      ],
      "metadata": {
        "id": "5EZXPYnWgPTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.pcolormesh(X,Y,Z)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ar3iuNr4zsMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test2 (Haar cascades):**"
      ],
      "metadata": {
        "id": "1kzfaDX4MtcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def non_max_suppression_slow(boxes, overlapThresh):\n",
        "\tif len(boxes) == 0:\n",
        "\t\treturn []\n",
        "\n",
        "\tpick = []\n",
        "\tx1 = boxes[:,0]\n",
        "\ty1 = boxes[:,1]\n",
        "\tx2 = boxes[:,2]\n",
        "\ty2 = boxes[:,3]\n",
        "\n",
        "\tarea = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "\tidxs = np.argsort(y2)\n",
        " \n",
        "  while len(idxs) > 0:\n",
        "\t\tlast = len(idxs) - 1\n",
        "\t\ti = idxs[last]\n",
        "\t\tpick.append(i)\n",
        "\t\tsuppress = [last]\n",
        "    for pos in xrange(0, last):\n",
        "\t\t\tj = idxs[pos]\n",
        "\n",
        "\t\t\txx1 = max(x1[i], x1[j])\n",
        "\t\t\tyy1 = max(y1[i], y1[j])\n",
        "\t\t\txx2 = min(x2[i], x2[j])\n",
        "\t\t\tyy2 = min(y2[i], y2[j])\n",
        "\n",
        "\t\t\tw = max(0, xx2 - xx1 + 1)\n",
        "\t\t\th = max(0, yy2 - yy1 + 1)\n",
        "\n",
        "\t\t\toverlap = float(w * h) / area[j]\n",
        "\n",
        "\t\t\tif overlap > overlapThresh:\n",
        "\t\t\t\tsuppress.append(pos)\n",
        "\n",
        "\t\tidxs = np.delete(idxs, suppress)\n",
        "\treturn boxes[pick]"
      ],
      "metadata": {
        "id": "oE7BOw9uk2K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "hog = cv2.HOGDescriptor()\n",
        "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
        "\n",
        "image = cv2.imread('/content/img3.jpg')\n",
        "\n",
        "height, width = image.shape[:2]\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + '/haarcascade_frontalface_default.xml')\n",
        "\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "min_size = int(max(0.001*width, 0.001*height))\n",
        "BBoxes = face_cascade.detectMultiScale(gray,\n",
        "                                      scaleFactor=1.1,\n",
        "                                      minNeighbors=2,\n",
        "                                      minSize=(min_size, min_size))\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "Z = []\n",
        "\n",
        "#BBoxes = non_max_suppression_slow(boundingBoxes, 0.3)\n",
        "\n",
        "for (x, y, w, h) in BBoxes:\n",
        "    cv2.rectangle(image, (x, y), \n",
        "                  (x + w, y + h), \n",
        "                  (0, 0, 255), 2)\n",
        "    X.append(x+w/2)\n",
        "    Y.append(y+h/2)\n",
        "    Z.append(1)\n",
        "  \n",
        "# cv2_imshow(image)\n",
        "# cv2.waitKey(0)   \n",
        "# cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Vpl0F9cILwuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = skimage.data.astronaut()\n",
        "test_image = skimage.color.rgb2gray(test_image)\n",
        "test_image = skimage.transform.rescale(test_image, 0.5)\n",
        "image = test_image[:160, 40:180]\n",
        "\n",
        "height, width = image.shape[:2]\n",
        "min_size = int(max(0.1*width, 0.1*height))\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + '/haarcascade_frontalface_default.xml')\n"
      ],
      "metadata": {
        "id": "W9fggx2KnKFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.pcolormesh(X,Y,Z)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Dd8k-_AEhey_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "TrainingSVM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}